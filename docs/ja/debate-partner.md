# 外部 AI ディベートパートナー

## 概要

リリース仕様書の作成後、外部の AI とディベート的な対話を行い、ビジョンとの整合を検証する。ディベートパートナーは意図的にプロジェクトの「外部」に置くことで、暗黙の前提を炙り出し、意思決定の質を高める。

## なぜ外部化するか

ディベートパートナーは、コンテキストを完全には共有していない相手として設計する。この「外部性」が以下の効果を生む:

### 暗黙の前提を炙り出す

省略できない説明が、自分が当然視していたことに気づかせる。「なぜそれが必要か」を一から説明する過程で、前提の穴が見つかる。

### 本質を平易に言い換える

専門用語や内部構造が通じないため、「何のためにやるのか」を自分の言葉で再構成する。

### 意思決定のラバーダッキング

技術レビュー（コードレビュー）は「コードの正しさ」を検証する。ディベートは「判断の正しさ」を検証する。この2つは補完関係にあり、統合しない。

## パートナーのコンテキスト境界

| 区分 | 内容 |
|------|------|
| **参照可能** | リポジトリのコードベース（構造・既存実装） |
| **持たない** | 開発セッションのリアルタイムコンテキスト（設計対話の経緯、試行錯誤等） |
| **渡すもの** | リリース仕様書（必要に応じて Vision 正本） |

この境界により、パートナーは技術詳細に入り込まず「なぜこれを作るのか」「ビジョンに沿っているか」という上位の問いに集中できる。

## 原則

1. **ポジションを取る**: 賛成/反対の立場を明確にして議論する。同調ではなく反論を求める
2. **反論に耐えたアイデアが残る**: 表面的な同意ではなく、攻撃されても成立する判断を目指す
3. **結論だけ記録**: ディベートログは対話チャネルに自然に残る。意思決定台帳には結論と「ディベートした」事実を記録
4. **パートナーは「壁打ち相手」であり「審判」ではない**: 最終判断は常に人間

## 運用フロー

ディベートは Phase 1（設計対話）の中に組み込まれる。

```
Phase 1: 設計対話（人間 + 実装 AI）
    ↓
    実装 AI: リリース仕様書ドラフト作成
    ↓
    実装 AI → ディベートパートナー: 論点 + リリース仕様書を投げる
    ↓
    パートナー: ビジョン整合の観点から批判・質問
    ↓
    実装 AI ↔ パートナー: 複数ラウンドの議論（必要に応じて）
    ↓
    実装 AI: ディベート結果をまとめる
    ↓
フィードバック会: リリース仕様書 + ディベート結果をセットで人間に提示
    ↓
人間: approve / reject / conditional
    ↓
Phase 2: 実装へ
```

### トリガー

- リリース仕様書ドラフトの完成後（Phase 1 → Phase 2 の境界）

### 応答の待ち方

- 実装 AI はディベートの応答を待つ（ブロッキング）
- 別のリリースなど独立したタスクがある場合は、別エージェントで並行して進めてよい

## 問いの設計

ディベートの質は「問いの設計」で決まる。良い問いは答えを求めていない。説明する過程で自分の中の矛盾や曖昧さに気づくことが目的。

### 設計原則

1. **Yes/No を避ける**: 立場を取らざるを得ない問いにする
2. **「正解」より「選択」**: 正解がある問いより、トレードオフを問う
3. **反論を前提にする**: 相手が攻撃してくることを織り込んだ問い方をする

### 設計対話時のテンプレート（Phase 1）

この段階が最も効果が高い。方向転換のコストが最小。

| 問い | 炙り出すもの |
|------|-------------|
| 「これを使うのは誰で、今どうしてるの？」 | ユーザー像の解像度 |
| 「それ、作らなくても解決する方法ない？」 | 実装バイアス |
| 「3ヶ月後もこれ使ってると思う？」 | 一時的な熱量 vs 持続的な価値 |
| 「この機能が成功したら、何が変わる？」 | ゴールの明確さ |
| 「Vision の『今はやらないこと』に抵触しない？」 | ビジョン整合 |

### レビュー時のテンプレート（Phase 3）

| 問い | 炙り出すもの |
|------|-------------|
| 「この変更を一言で説明して」 | スコープの適切さ |
| 「ユーザーはこの変更に気づく？気づいたら嬉しい？」 | 体験への影響 |
| 「これを入れなかったらどうなる？」 | 本当に必要かの検証 |

### フィードバック会のテンプレート

| 問い | 炙り出すもの |
|------|-------------|
| 「今日一番迷った判断は？」 | 迷いの言語化 |
| 「今の方向性を誰かに説明するとしたら、何て言う？」 | Vision の定着度 |

### アンチパターン

| パターン | 問題 |
|---------|------|
| 確認を求める問い（「この設計でいいよね？」） | 同調を誘い、内省が起きない |
| 技術詳細に入り込む問い（「API の引数の型は？」） | それはコードレビューの仕事 |
| 答えが自明な問い（「ユーザー体験は大事だよね？」） | 誰も反対しないので議論にならない |

## 納得の閾値

ディベート結果の最終判断は人間（フィードバック会）が行う。実装 AI はディベート結果を整理・要約して人間に提示する。

- **Go 基準**: ディベート結果を見て、ビジョンとの整合に納得できた → approve
- **Stop 基準**: ディベートで指摘された懸念が解消されていない → reject / conditional
- **つまり**: ディベートパートナーは「鏡」であり「審判」ではない。判断するのは人間

## 実装パターン

ディベートのインターフェースはテキスト対話ができれば手段を問わない。特定のプラットフォームに依存しない設計とする。

### パターン 1: チャットプラットフォーム経由

```
実装 AI（Claude Code）→ Discord/Slack → 外部 AI ボット
```

- 既存のチャットインフラを活用
- 対話ログが自然に残る
- 非同期コミュニケーションに適する

### パターン 2: API 直接呼び出し

```
実装 AI（Claude Code）→ 外部 AI の API
```

- 低レイテンシ
- プログラマティックな制御が可能
- 対話ログは別途保存が必要

### パターン 3: 別の Claude Code セッション

```
Claude Code（実装）→ Claude Code（レビュー/ディベート）
```

- 同一ツールチェーンで完結
- コンテキストの明示的な制御が必要

### 推奨: 異なる AI モデルの組み合わせ

ディベートの効果を最大化するには、異なる AI モデル/プロバイダを組み合わせることを推奨する。同一モデルでは思考パターンが類似し、見落としが共通する傾向がある。

| 組み合わせ例 | 期待される多様性 |
|-------------|----------------|
| Claude + GPT | アーキテクチャの異なるモデル |
| Claude + Gemini | 訓練データの異なるモデル |
| 同一モデル（異なるプロンプト） | 視点の多様性（最小限） |

## 意思決定台帳への記録

ディベートを行った場合、意思決定台帳に以下を記録する:

```markdown
## D-YYYYMMDD-NN: <意思決定タイトル>
- debate: <チャネル> YYYY-MM-DD
- summary: <ディベートで出た主要な論点と結論>
- decision: <人間の最終判断>
```

## 運用の進化

対話チャネルの運用、問いの型、効果的な問いの立て方は実践を通じて学び、プロセスに反映する。ディベートの質は経験とともに向上する。

## 関連ドキュメント

- [VDD.md](./VDD.md) — VDD の仕様（ディベートパートナーセクション）
- [qa-layers.md](./qa-layers.md) — QA の3層モデル（Layer 2 との補完関係）
- [decision-authority-matrix.md](./decision-authority-matrix.md) — 意思決定権限
